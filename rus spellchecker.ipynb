{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = ['gent', 'datv', 'accs', 'ablt', 'loct', 'plur']\n",
    "\n",
    "#все возможные формы существительных\n",
    "def inflect(word, morph, tags, i):\n",
    "    nouns_inflected = []\n",
    "    noun_parsed = morph.parse(word)[i]\n",
    "    for tag in tags:\n",
    "        try:\n",
    "            n_sing = noun_parsed.inflect({tag})[0]\n",
    "            nouns_inflected.append(n_sing)\n",
    "            n_plur = noun_parsed.inflect({'plur', tag})[0]\n",
    "            nouns_inflected.append(n_plur)\n",
    "        except:\n",
    "            pass\n",
    "    return list(set(nouns_inflected))\n",
    "\n",
    "#для омонимичных форм (pymorphy разбирает \"начало\", в первую очередь, как глагол, только потом существительное)\n",
    "def get_only_nouns(word, morph):\n",
    "    noun_parsed = morph.parse(word)[0]\n",
    "    if \"NOUN\" in noun_parsed.tag:\n",
    "        try:\n",
    "            nouns = inflect(word, morph, tags, 0)\n",
    "            return nouns\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            nouns = inflect(word, morph, tags, 1)\n",
    "            return nouns\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = open('C:/Users/1/Desktop/freqrnc2011.csv', 'r', encoding='utf-8')\n",
    "lines = s.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#s - обозначение существительного в частотном словаре\n",
    "#неначальные формы получают частоту начальной\n",
    "dic = {}\n",
    "\n",
    "for line in lines:\n",
    "    tokens = line.split(\"\\t\")\n",
    "    if tokens[1] == \"s\":\n",
    "        tokens[0] = tokens[0].strip('\"')\n",
    "        if tokens[0] not in dic.keys():\n",
    "            dic[tokens[0]] = float(tokens[2])\n",
    "        else:\n",
    "            dic[tokens[0]] += float(tokens[2])\n",
    "        if get_only_nouns(tokens[0], morph) != None:\n",
    "            for item in get_only_nouns(tokens[0], morph):\n",
    "                if item not in dic.keys():\n",
    "                    dic[item] = float(tokens[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#все \"ё\" заменяются на \"е\" (в словаре \"актер\", а не \"актёр\")\n",
    "dic_new = {}\n",
    "for key, value in dic.items():\n",
    "    if \"ё\" in key:\n",
    "        key = key.replace(\"ё\",\"е\")\n",
    "        dic_new[key] = value\n",
    "    else:\n",
    "        dic_new[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = open('C:/Users/1/Desktop/dictionary_spell.tsv', 'w', encoding='utf-8')\n",
    "for key, value in dic_new.items():\n",
    "    k.write(key + \"\\t\" + str(value) + \"\\n\")\n",
    "k.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тестовом файле 10 ошибок, которые должен исправить спеллчекер: касметики, прадукт, рикламу, асобеностей, преставки, инцедентов, карпараций, сикунду, растаяние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P(word, N=sum(dic_new.values())): \n",
    "    return dic_new[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words):\n",
    "    return set(w for w in words if w in dic.keys())\n",
    "\n",
    "def edits1(word):\n",
    "    letters    = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = open('C:/Users/1/Desktop/spellcheck_test.txt', 'r', encoding='utf-8')\n",
    "test = v.read()\n",
    "words_test = test.split()\n",
    "nouns_test = []\n",
    "for word in words_test:\n",
    "    if word.islower() == True:\n",
    "        word = word.strip(\".,:;!?()\")\n",
    "        p = morph.parse(word)[0]\n",
    "        if \"NOUN\" in p.tag:\n",
    "            if any(str.isdigit(c) for c in word) == False:\n",
    "                nouns_test.append(word.strip(\"()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "касметики косметики\n",
      "прадукт продукт\n",
      "годы году\n",
      "рикламу рекламу\n",
      "геймера гейзера\n",
      "геймеров гейзеров\n",
      "асобеностей особенностей\n",
      "холодным холодом\n",
      "любой людей\n",
      "поп-звезд поп-звезда\n",
      "преставки приставки\n",
      "шутере шулере\n",
      "инцедентов инцидентов\n",
      "геймера гейзера\n",
      "гигабайтах мегабайтах\n",
      "трансформер транспортер\n",
      "килограмма килограммы\n",
      "гигабайтами мегабайтами\n",
      "килограмма килограммы\n",
      "карпараций корпораций\n",
      "им имя\n",
      "планетой планетов\n",
      "планетой планетов\n",
      "сикунду секунду\n",
      "растаяние раскаяние\n"
     ]
    }
   ],
   "source": [
    "for item in nouns_test:\n",
    "    try:\n",
    "        if correction(item) != item:\n",
    "            print(item + \" \" + correction(item))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "супергерой суперменов\n",
      "касметики косметики\n",
      "прадукт продукт\n",
      "годы ягоды\n",
      "рикламу рекламу\n",
      "геймера гейзера\n",
      "геймеров гейзеров\n",
      "героя-мужчину мужчину\n",
      "асобеностей особенностей\n",
      "слэшера эсера\n",
      "мини-мюзикл мини-юбку\n",
      "холодным холодком\n",
      "любой юбкой\n",
      "платформеров платформой\n",
      "поп-звезд поп-звезда\n",
      "преставки приставки\n",
      "платформера-паззла платформах\n",
      "людям-грибам любимицам\n",
      "шутере шушере\n",
      "инцедентов инцидентов\n",
      "геймера гейзера\n",
      "геймплея гейме\n",
      "ноутбуков-трансформеров бронетранспортеров\n",
      "гигабайтах мегабайтах\n",
      "трансформер транспортер\n",
      "килограмма килограммах\n",
      "гигабайтами мегабайтами\n",
      "килограмма килограммах\n",
      "карпараций корпораций\n",
      "им эм\n",
      "планетой планеткой\n",
      "планетой планеткой\n",
      "магнитосферы магнитофоны\n",
      "сикунду секунду\n",
      "растаяние раскаяние\n"
     ]
    }
   ],
   "source": [
    "for noun in nouns_test:\n",
    "    arr = []\n",
    "    for key, value in dic_new.items():\n",
    "        d = Levenshtein.distance(noun, key)\n",
    "        arr.append((key, d))\n",
    "    sorted_arr = sorted(arr, key=lambda tup: tup[1])\n",
    "\n",
    "    arr_new = []\n",
    "    for item in sorted_arr:\n",
    "        if item[1] == sorted_arr[0][1]:\n",
    "            arr_new.append((item[0], float(dic_new[item[0]])))\n",
    "            \n",
    "    arr_final = []\n",
    "    if len(arr_new) == 1:\n",
    "        if noun != sorted_arr[0][0]:\n",
    "           print (noun + \" \" + sorted_arr[0][0])\n",
    "    else:\n",
    "        i = 0\n",
    "        while i < len(arr_new) - 1:\n",
    "            if float(arr_new[i+1][1]) > float(arr_new[i][1]):\n",
    "                x = arr_new[i+1][0]\n",
    "            else:\n",
    "                x = arr_new[i][0]\n",
    "            i += 1\n",
    "        print (noun + \" \" + x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
